"""
OpenAI Service for GPT-4o Audio Preview
Unified voice and text processing using latest GPT-4o audio capabilities
"""

import base64
import logging
import openai
from typing import Dict, List, Any, Optional, Union, AsyncGenerator
from datetime import datetime
import json
import asyncio
import io

logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self, api_key: str, base_url: Optional[str] = None):
        """
        Initialize OpenAI service with GPT-4o Audio support
        
        Args:
            api_key: OpenAI API key
            base_url: Optional custom base URL for OpenAI API
        """
        if base_url:
            self.client = openai.OpenAI(api_key=api_key, base_url=base_url)
        else:
            self.client = openai.OpenAI(api_key=api_key)
        self.api_key = api_key
        logger.info("ğŸµ OpenAI Service initialized with GPT-4o Audio Preview support")

    async def process_voice_input_for_matching(
        self, 
        audio_data: Union[bytes, str],
        audio_format: str = "wav",
        language: str = "en-US"
    ) -> Dict[str, Any]:
        """
        Use GPT-4o Audio to directly process user voice input, extract topics and generate hashtags
        
        New workflow: Audio â†’ GPT-4o Audio â†’ Understand content + Generate hashtags + Audio response
        Replaces: Audio â†’ STT â†’ GPT â†’ Hashtags + TTS
        
        Args:
            audio_data: Audio data (bytes or base64 string)
            audio_format: Audio format (wav, mp3, etc.)
            language: Language preference
            
        Returns:
            {
                "understood_text": "Content spoken by the user",
                "extracted_topics": ["AI", "Entrepreneurship"],  
                "generated_hashtags": ["#AI", "#Entrepreneurship", "#Tech"],
                "match_intent": "Wants to find someone to talk about AI and entrepreneurship",
                "audio_response": "Base64 encoded AI response audio",
                "text_response": "Okay, I understand you want to talk about AI and entrepreneurship, matching you now..."
            }
        """
        try:
            logger.info("ğŸ™ï¸ Processing voice input with GPT-4o Audio for matching...")
            
            # Convert audio to base64 if needed
            if isinstance(audio_data, bytes):
                audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            else:
                audio_base64 = audio_data
            
            # Use GPT-4o Audio Preview for unified processing
            response = self.client.chat.completions.create(
                model="gpt-4o-audio-preview",
                modalities=["text", "audio"],
                audio={"voice": "alloy", "format": "wav"},
                messages=[
                    {
                        "role": "system", 
                        "content": f"""You are an intelligent voice matching assistant. Users will tell you what topics they want to discuss, please:

1. Understand the user's voice content
2. Extract main topics (in English)
3. Generate English hashtags (for matching algorithm)
4. Respond in {language} to confirm understanding and start matching

Please return in JSON format:
{{
    "understood_text": "Specific content spoken by the user",
    "extracted_topics": ["Topic1", "Topic2"],
    "generated_hashtags": ["#hashtag1", "#hashtag2"],
    "match_intent": "Summary of user's matching intent"
}}

Also respond with a friendly voice to confirm understanding and inform that matching is in progress."""
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "input_audio",
                                "input_audio": {
                                    "data": audio_base64,
                                    "format": audio_format
                                }
                            }
                        ]
                    }
                ]
            )
            
            # Extract response
            message = response.choices[0].message
            
            # Parse JSON response from text
            result_data = {}
            if message.content:
                try:
                    result_data = json.loads(message.content)
                except json.JSONDecodeError:
                    logger.warning("Failed to parse JSON response, extracting manually")
                    result_data = {
                        "understood_text": message.content,
                        "extracted_topics": ["General topic"],
                        "generated_hashtags": ["#general"],
                        "match_intent": "Wants to chat"
                    }
            
            # Add audio response
            result_data.update({
                "audio_response": message.audio.data if message.audio else None,
                "text_response": message.content,
                "audio_transcript": message.audio.transcript if message.audio else None,
                "processing_time": datetime.utcnow().isoformat()
            })
            
            logger.info(f"âœ… Voice matching processed: {result_data.get('extracted_topics', [])}")
            return result_data
            
        except Exception as e:
            logger.error(f"âŒ Voice input processing failed: {e}")
            return {
                "understood_text": "Sorry, I didn't understand what you said",
                "extracted_topics": ["General topic"],
                "generated_hashtags": ["#general"],
                "match_intent": "General chat",
                "audio_response": None,
                "text_response": f"Error processing voice input: {str(e)}",
                "error": str(e)
            }

    async def moderate_room_conversation(
        self,
        audio_data: Optional[Union[bytes, str]] = None,
        text_input: Optional[str] = None,
        conversation_context: List[Dict[str, Any]] = None,
        room_participants: List[str] = None,
        moderation_mode: str = "active_host"
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨GPT-4o Audioä½œä¸ºæˆ¿é—´AIä¸»æŒäººå’Œç§˜ä¹¦
        
        åŠŸèƒ½ï¼š
        - å®æ—¶è¯­éŸ³å¯¹è¯
        - Fact check
        - è¯é¢˜å»ºè®®
        - æ°”æ°›è°ƒèŠ‚
        - å†…å®¹å®¡æ ¸
        
        Args:
            audio_data: ç”¨æˆ·è¯­éŸ³ï¼ˆå¦‚æœæœ‰ï¼‰
            text_input: æ–‡å­—è¾“å…¥ï¼ˆå¦‚æœæœ‰ï¼‰
            conversation_context: å¯¹è¯ä¸Šä¸‹æ–‡
            room_participants: æˆ¿é—´å‚ä¸è€…
            moderation_mode: ä¸»æŒæ¨¡å¼ (active_host, secretary, fact_checker)
            
        Returns:
            AIä¸»æŒäººçš„å›å¤ï¼ˆéŸ³é¢‘+æ–‡å­—+å»ºè®®ï¼‰
        """
        try:
            logger.info(f"ğŸ­ AI moderating room conversation in {moderation_mode} mode...")
            
            # Build conversation context
            context_messages = [
                {
                    "role": "system",
                    "content": f"""You are an intelligent room host and chat secretary. Current mode: {moderation_mode}

Your responsibilities:
1. ğŸª Engage the conversation: Actively provide topics when the conversation is cold
2. ğŸ’¡ Fact Check: When participants mention potentially inaccurate information, provide friendly verification
3. ğŸ’¬ Comment: Respond appropriately to conversation content and provide suggestions
4. ğŸ›¡ï¸ Content Moderation: Ensure the conversation is friendly and harmonious
5. ğŸ†˜ Assistive Guidance: Help participants communicate better

Current room participants: {', '.join(room_participants or [])}

Please provide an appropriate response based on the input content, which can be a voice response, a text suggestion, or a topic recommendation.
The response should be natural, friendly, and helpful."""
                }
            ]
            
            # Add conversation history
            if conversation_context:
                context_messages.extend(conversation_context[-10:])  # Last 10 messages
            
            # Build user message
            user_content = []
            if audio_data:
                if isinstance(audio_data, bytes):
                    audio_base64 = base64.b64encode(audio_data).decode('utf-8')
                else:
                    audio_base64 = audio_data
                    
                user_content.append({
                    "type": "input_audio",
                    "input_audio": {
                        "data": audio_base64,
                        "format": "wav"
                    }
                })
            
            if text_input:
                user_content.append({
                    "type": "input_text",
                    "text": text_input
                })
            
            context_messages.append({
                "role": "user",
                "content": user_content if user_content else [{"type": "input_text", "text": "Please assist in moderating the conversation"}]
            })
            
            # Generate AI moderator response
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model="gpt-4o-audio-preview",
                modalities=["text", "audio"],
                audio={"voice": "nova", "format": "wav"},  # ä½¿ç”¨æ›´æ´»æ³¼çš„å£°éŸ³
                messages=context_messages,
                max_tokens=300
            )
            
            message = response.choices[0].message
            
            return {
                "ai_response": {
                    "text": message.content,
                    "audio": message.audio.data if message.audio else None,
                    "audio_transcript": message.audio.transcript if message.audio else None
                },
                "moderation_type": moderation_mode,
                "suggestions": self._extract_suggestions(message.content or ""),
                "timestamp": datetime.utcnow().isoformat(),
                "participants": room_participants
            }
            
        except Exception as e:
            logger.error(f"âŒ Room moderation failed: {e}")
            return {
                "ai_response": {
                    "text": f"AI host encountered an issue: {str(e)}",
                    "audio": None
                },
                "error": str(e)
            }

    def _extract_suggestions(self, ai_text: str) -> List[str]:
        """ä»AIå›å¤ä¸­æå–å»ºè®®"""
        suggestions = []
        if "å»ºè®®" in ai_text:
            suggestions.append("ğŸ’¡ AI provided a suggestion")
        if "è¯é¢˜" in ai_text:
            suggestions.append("ğŸ¯ New topic recommendation")
        if "äº‹å®" in ai_text or "ä¿¡æ¯" in ai_text:
            suggestions.append("ğŸ” Fact checking")
        return suggestions
    
    def health_check(self) -> Dict[str, Any]:
        """
        æ£€æŸ¥OpenAIæœåŠ¡å¥åº·çŠ¶æ€
        
        Returns:
            å¥åº·çŠ¶æ€ä¿¡æ¯
        """
        try:
            # æ”¹ä¸ºä½¿ç”¨ä¼ ç»Ÿçš„TTS APIæ¥æµ‹è¯•è¿æ¥ï¼Œé¿å…GPT-4o Audioçš„å¤æ‚å‚æ•°
            response = self.client.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input="Health check test"
            )
            
            return {
                "status": "healthy",
                "service": "openai_tts",
                "model": "tts-1",
                "timestamp": datetime.utcnow().isoformat()
            }
        except Exception as e:
            logger.error(f"âŒ OpenAI health check failed: {e}")
            return {
                "status": "unhealthy",
                "service": "openai_gpt4o_audio",
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }
    
    async def text_to_speech(self, text: str, voice: str = "alloy", speed: float = 1.0) -> bytes:
        """
        ä½¿ç”¨OpenAI TTS APIç”Ÿæˆè¯­éŸ³
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            voice: è¯­éŸ³ç±»å‹
            speed: è¯­éŸ³é€Ÿåº¦
            
        Returns:
            éŸ³é¢‘æ•°æ®ï¼ˆbytesï¼‰
        """
        try:
            logger.info(f"ğŸ”Š Generating TTS: {text[:50]}...")
            
            # ä½¿ç”¨ä¼ ç»Ÿçš„TTS APIï¼Œæ›´ç¨³å®šå¯é 
            response = await asyncio.to_thread(
                lambda: self.client.audio.speech.create(
                    model="tts-1-hd",  # é«˜è´¨é‡TTS
                    voice=voice,
                    input=text,
                    speed=speed
                )
            )
            
            # ç›´æ¥è¿”å›éŸ³é¢‘å­—èŠ‚æ•°æ®
            audio_bytes = response.content
            logger.info("âœ… TTS generated successfully")
            return audio_bytes
                
        except Exception as e:
            logger.error(f"âŒ TTS generation failed: {e}")
            raise